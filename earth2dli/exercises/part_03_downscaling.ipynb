{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<br>\n",
    "<a href=\"https://www.nvidia.com/en-us/training/\">\n",
    "    <div style=\"width: 55%; background-color: white; margin-top: 50px;\">\n",
    "    <img src=\"https://dli-lms.s3.amazonaws.com/assets/general/nvidia-logo.png\"\n",
    "         width=\"400\"\n",
    "         height=\"186\"\n",
    "         style=\"margin: 0px -25px -5px; width: 300px\"/>\n",
    "</a>\n",
    "<h1 style=\"line-height: 1.4;\"><font color=\"#76b900\"><b>Applying AI Weather Models With NVIDIA Earth-2</h1>\n",
    "<h2><b>Part 3:</b> Downscaling</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "The weather data generated by global AI models like FourCastNet (SFNO) is usually confined to a 0.25° grid, which roughly corresponds to a 25-km resolution at the Tropic Circles. The primary reason for using this grid for global AI weather models is that the vast data archive of ERA5 is readily available at this resolution and can be leveraged for massive data-driven model training. Numerical assimilation and forecast systems often operate at lower resolutions. For example, the global ECMWF HRES forecast is available on a 0.1° grid (approximately 10 km) and a Cubic Octahedral (O1280) grid (approximately 9 km). Regional models, like the Weather Research and Forecasting (WRF) model or the Icosahedral Nonhydrostatic (ICON) model, are often run on resolutions between 1 km and 3 km. Many applications require these kilometer-scale or even sub-kilometer resolutions. \n",
    "\n",
    "Training and running high-resolution models at a global scale is resource intensive. Alternatively, we can use statistical downscaling models. These models are trained to go from lower resolutions (like 25 km) to higher resolutions (like 2 km). Statistical downscaling is a common alternative to dynamical downscaling (i.e., running regional numerical models conditioned on global inputs) also for numerical weather prediction. With the newest developments in the AI space, we can now build much more powerful statistical downscaling models.\n",
    "\n",
    "[CorrDiff](https://arxiv.org/abs/2309.15214) employs a two-step approach to simultaneously map from low- to high-resolution data and synthesize new variables not present in the input. The first step uses UNet regression to predict the conditional mean of the output field. This helps in dealing with the significant distribution shift between inputs and outputs, such as wind speed peaks hiding between grid points. The second step then recovers a physically realistic representation using a diffusion model. Diffusion models are trained to iteratively remove noise from the input and are able to reveal fine details that the regression alone could not capture.\n",
    "\n",
    "![CorrDiff Taiwan](./images/corrdiff.jpg \"CorrDiff Taiwan\")\n",
    "\n",
    "In the third part of our workshop, we will develop a workflow applying CorrDiff, trained over Taiwan, to a forecast produced by FourCastNet (SFNO). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import xarray as xr\n",
    "from earth2studio.utils.coords import map_coords, split_coords\n",
    "from earth2studio.data import fetch_data, GFS\n",
    "from earth2studio.lexicon import GFSLexicon\n",
    "from earth2studio.io import KVBackend\n",
    "from earth2studio.models.dx import CorrDiffTaiwan\n",
    "from earth2studio.models.px import SFNO\n",
    "from earth2studio.utils.time import to_time_array\n",
    "from tqdm import tqdm\n",
    "\n",
    "from plot import plot_downscaled_forecast, plot_downscaled_samples, plot_downscaling, plot_pop, plot_pop_t2m\n",
    "from utils import make_quarter_degree\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "The version of CorrDiff covering Taiwan was developed together with the Taiwan Central Weather Authority (CWA), which also provided the high-resolution regional weather data used for training. The model takes 12 variables on a 25 km grid and produces four variables on a 2 km grid. It is available through Earth2Studio and can be loaded exactly like the models we have dealt with before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrdiff = CorrDiffTaiwan.load_model(CorrDiffTaiwan.load_default_package())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "This time, we want to develop an inference workflow from scratch instead of using one of the predefined workflows in Earth2Studio. We will couple FourCastNet (SFNO) to CorrDiff-Taiwan in a way that FourCastNet (SFNO) produces a forecast at 25 km and CorrDiff Taiwan downscales the forecast to 2 km. We can load our forecast model as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn = SFNO.load_model(SFNO.load_default_package())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "For accelerated inference, we move our models to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "fcn = fcn.to(device)\n",
    "corrdiff = corrdiff.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We will initialize our forecast from GFS data instead of ERA5 data this time. This will make it easy to switch to a live forecasting setup at a later point in time. Our forecast will cover the period when a heatwave hit Taiwan in July 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs = GFS()\n",
    "start_time = np.datetime64(\"2024-07-01 12:00:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Data retrieval works as before, with the help of `fetch_data`. We pass our data source, the start time, input variables, and lead time (which is 0 hours for the input). We also specify our GPU as the target device so that the data will already be available to our models once we start inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_coords = fcn.input_coords()\n",
    "\n",
    "x, coords = fetch_data(\n",
    "    source=gfs,\n",
    "    time=to_time_array([start_time]),\n",
    "    variable=input_coords[\"variable\"],\n",
    "    lead_time=input_coords[\"lead_time\"],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Next, let’s define how long we want to forecast into the future. We will cover 12 time intervals of 6 hours each. Remember that the pretrained version of FourCastNet (SFNO) produces forecasts in steps of 6 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 12\n",
    "lead_time = np.array([np.timedelta64(6 * i, \"h\") for i in range(nsteps + 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "CorrDiff is a diffusion model, so it can produce a distribution of output scenarios. This allows us to create a high-resolution ensemble from a single low-resolution input and get a probabilistic view on the small-scale weather. We set the number of samples to produce per time step to 4. Note that we will create a deterministic forecast and only produce an ensemble during downscaling. To take things further, we could use ensembles during both forecasting and downscaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrdiff.number_of_samples = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Now, we can set up our data store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "io = KVBackend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "We tell the IO backend upfront what kind of data to expect so we can efficiently write to the output file during inference. For the coords, we supply the start times (a single start time in our case), the lead times (1 initial condition plus 12 forecast steps), the number of samples, and the geographic coordinates. Finally, we create one array per output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_coords = corrdiff.output_coords(corrdiff.input_coords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_coords = OrderedDict(\n",
    "    {\n",
    "        \"time\": to_time_array([start_time]),\n",
    "        \"lead_time\": lead_time,\n",
    "        \"sample\": output_coords[\"sample\"],\n",
    "        \"lat\": output_coords[\"lat\"],\n",
    "        \"lon\": output_coords[\"lon\"],\n",
    "    }\n",
    ")\n",
    "io.add_array(io_coords, output_coords[\"variable\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "We are now ready to run our inference workflow. In the code below, we make use of `map_coords` to select the input variables required for FourCastNet (SFNO) and CorrDiff. The forecast is handled by an iterator, and we immediately apply CorrDiff at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, coords = map_coords(x, coords, fcn.input_coords())\n",
    "fc_iterator = fcn.create_iterator(x, coords)\n",
    "\n",
    "with tqdm(total=nsteps + 1, desc=\"Running inference\") as pbar:\n",
    "    for step, (x_i, coords_i) in enumerate(fc_iterator):\n",
    "        x_i, coords_i = map_coords(x_i, coords_i, corrdiff.input_coords())\n",
    "        x_i, coords_i = corrdiff(x_i, coords_i)\n",
    "        io.write(*split_coords(x_i, coords_i))\n",
    "        pbar.update(1)\n",
    "        if step == nsteps:\n",
    "            break\n",
    "\n",
    "hi_res = io.to_xarray()  # load as xarray Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "For comparison, we now also retrieve the corresponding low-resolution GFS data. The code should look familiar from the previous part. We convert the output from `fetch_data` (PyTorch tensor and corresponding coords) to an xarray `Dataset` for convenience. The low-resolution data is limited to the window covered by CorrDiff Taiwan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "lo_res = xr.DataArray(\n",
    "    *fetch_data(\n",
    "        source=gfs,\n",
    "        time=to_time_array([start_time]),\n",
    "        variable=[v for v in output_coords[\"variable\"] if v in GFSLexicon.VOCAB],\n",
    "        lead_time=hi_res.lead_time.values,\n",
    "    )\n",
    ").to_dataset(\"variable\")\n",
    "\n",
    "# Limit to the window covered by our model\n",
    "lat_from, lat_to = corrdiff.input_coords()[\"lat\"][[0, -1]]\n",
    "lon_from, lon_to = corrdiff.input_coords()[\"lon\"][[0, -1]]\n",
    "lo_res = lo_res.sel(lat=make_quarter_degree(lat_from, lat_to), lon=make_quarter_degree(lon_from, lon_to))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Taiwan is operating several offshore wind farms in the Taiwan Strait, and additionally onshore wind farms throughout the country. We may be interested in the expected energy production from these wind farms, and CorrDiff can help us get a more detailed picture on local wind speeds. The plots below compare GFS in the top row and the downscaled CorrDiff result in the bottom row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_wind_speed(ds):\n",
    "    return (ds.u10m ** 2 + ds.v10m ** 2) ** 0.5\n",
    "\n",
    "plot_downscaling(lo_res.assign(s10m=_get_wind_speed), hi_res.assign(s10m=_get_wind_speed), \"s10m\", start_time, cb_label=\"Wind speed (m/s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "As explained above, CorrDiff can not only generate higher resolution data for input variables but also synthesize new variables. In addition to 2-meter temperature and 10-meter wind speeds, which are present in the input data, CorrDiff Taiwan calculates 1-hour maximum radar reflectivity (`mrr`). Radar reflectivity is an important proxy for rain intensity. The plots below show the results over several timesteps. High humidity before rainfall is what made the heatwave Taiwan experienced in July 2024 especially uncomfortable for people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downscaled_forecast(hi_res, \"mrr\", start_time, float(lo_res.lon[len(lo_res.lon) // 2]), cb_label=\"MRR (dBZ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "We can compare different ensemble members to distinguish areas of higher uncertainty from areas of lower uncertainty. The overall pattern of small-scale weather looks similar across samples, but each is a separate physically realistic representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downscaled_samples(hi_res, \"mrr\", start_time, float(lo_res.lon[len(lo_res.lon) // 2]), cb_label=\"MRR (dBZ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "We will have a closer look at temperature now. To make the results more intuitive, choose whether you want to work with °C or °F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = \"°C\"\n",
    "\n",
    "t2m_converters = {\n",
    "    \"°C\": lambda ds: ds.t2m - 273.15,\n",
    "    \"°F\": lambda ds: (ds.t2m - 273.15) * 9/5 + 32,\n",
    "    \"K\": lambda ds: ds\n",
    "}\n",
    "\n",
    "lo_res = lo_res.assign(t2m=t2m_converters[unit])\n",
    "hi_res = hi_res.assign(t2m=t2m_converters[unit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "The plots below again compare GFS with CorrDiff results, this time for 2-meter temperature. Reported temperatures reached up to 38°C (100°F) in the lower regions of the country. On the other hand, the temperature drop high up in the mountainous regions of Taiwan becomes clearly visible after downscaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downscaling(lo_res, hi_res, \"t2m\", start_time, normalize=True, cb_label=f\"Temperature [{unit}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "As a first indicator of energy consumption through, e.g., air conditioning, we will now have a look at the temperature weighted by the regional population. We have prepared weights based on recent census results that match the resolution of GFS and CorrDiff Taiwan, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_lo = np.load(\"./data/pop_tw_lo.npy\")\n",
    "msk_lo = (pop_lo > 0).astype(np.float32)\n",
    "msk_lo /= msk_lo.sum()\n",
    "\n",
    "pop_hi = np.load(\"./data/pop_tw_hi.npy\")\n",
    "msk_hi = (pop_hi > 0).astype(np.float32)\n",
    "msk_hi /= msk_hi.sum()\n",
    "\n",
    "plot_pop(pop_lo, msk_lo, pop_hi, msk_hi, lo_res.lon, lo_res.lat, hi_res.lon, hi_res.lat, float(lo_res.lon[len(lo_res.lon) // 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Let's multiply the weights by the temperature values and calculate the expected temperature experienced by the population of Taiwan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_t2m_gfs = (lo_res.t2m * pop_lo).sum(dim=\"lat\").sum(dim=\"lon\")\n",
    "msk_t2m_gfs = (lo_res.t2m * msk_lo).sum(dim=\"lat\").sum(dim=\"lon\")\n",
    "\n",
    "pop_t2m_corrdiff = (hi_res.t2m * pop_hi).sum(dim=\"ilat\").sum(dim=\"ilon\")\n",
    "msk_t2m_corrdiff = (hi_res.t2m * msk_hi).sum(dim=\"ilat\").sum(dim=\"ilon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "The plot below shows the results over the course of the fourcast. The diurnal cycle with higher temperatures during the day is clearly visible. Still, temperatures stayed high at night, which must have caused considerable heat stress. The two lines corresponding to the masks not taking population into account run lower than the lines based on population. This is because, without weighting by population, the cooler mountain regions of Taiwan, which are not inhabited as much as the coastal regions, have a higher influence on the result. The result produced by CorrDiff temperatures is also slightly lower compared to GFS temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pop_t2m(pop_t2m_gfs, msk_t2m_gfs, pop_t2m_corrdiff, msk_t2m_corrdiff, ylabel=f\"Temperature [{unit}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "We hope you have enjoyed our workshop on NVIDIA Earth-2. You are now prepared to build your own AI weather applications with [Earth2Studio](https://github.com/NVIDIA/earth2studio). You can find more hands-on examples in the [User Guide](https://nvidia.github.io/earth2studio/userguide/index.html). For training your own AI weather models, check out the [examples in the NVIDIA Modulus](https://github.com/NVIDIA/modulus/tree/main/examples) repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
